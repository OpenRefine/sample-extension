<div class="dialog-frame llm-dialog" style="width: 700px">
    <div class="dialog-header" bind="llmSettingsContainer"></div>
    <div class="dialog-body" bind="dialogBody">
        <p bind="explainLLMSetup"></p>
        <div class="llm-list-wrapper">
            <table class="llm-providers-table" >
                <thead>
                <tr>
                    <th bind="llmLabel">Name</th>
                    <th bind="llmModel">Model</th>
                    <th bind="llmApiUrl">API URL</th>
                    <th bind="llmActions">Actions</th>
                </tr>
                </thead>
                <tbody bind="listLLMProviders">
                <!-- dynamically generated -->
                </tbody>
            </table>
        </div>
        <div class="llm-about">
            <p>You'll need to use the format:</p>
                <ul>
                    <li><code>https://api.openai.com/v1/chat/completions/</code> [Remote OpenAI endpoints]</li>
                    <li>or <code>http://localhost:11434/v1/chat/completions/</code> [Local OpenAI endpoints, e.g. Ollama]</li>
                </ul> 
            <p>Note: This extension is still in development and not all OpenAI API endpoints may work yet (e.g. LMStudio). For more information on how to best tweak prompts and parameters to get the most out of `llm-extension`, read more about parameters at the <a href="https://github.com/sunilnatraj/llm-extension" target="_blank">llm-extension repository on Github</a>.</p>
        </div>
    </div>
    <div class="dialog-footer" style="justify-content: space-between" bind="dialogFooter">
        <div class="dialog-footer-bg">
            <button class="button" bind="addButton"></button>
        </div>
        <div class="dialog-footer-bg">
            <button class="button button-primary" bind="closeButton"></button>
        </div>
    </div>
</div>
